1.关于随机梯度和批量梯度：
随机梯度下降算法：在样本训练过程中一次一次进行更新，适用于样本量比较大的情况，但是不一会收敛到局部最小值，可能在最小值附近来回震荡。
批量梯度下降算法：在样本训练过程中进行梯度累计，最后整体进行更新，比较适合小样本，能够收敛到局部最小值，如果是线性回归问题，可以收敛到全局最小值。
梯度下降在到最小值点的时候收敛速度会变慢，而且该方法对初始值选取很敏感
